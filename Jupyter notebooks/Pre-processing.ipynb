{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # import necessary libraries\n",
    "    import subprocess\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import itertools\n",
    "    import numpy as np\n",
    "    import seaborn as sns\n",
    "    import glob\n",
    "    import cv2\n",
    "\n",
    "    from sklearn import datasets, linear_model\n",
    "    from sklearn.metrics import mean_squared_error, r2_score\n",
    "    from sklearn import preprocessing\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from scipy import stats\n",
    "    from scipy.stats import norm\n",
    "    from PIL import ImageFile, Image\n",
    "    from matplotlib import image,pyplot\n",
    "    from PIL import ImageFile, Image\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from scipy.stats import zscore\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# training,test,devel data index extraction from partition file\n",
    "partition  = pd.read_csv(f\"/Thesis_data/c3_muse_stress_2022/metadata/partition.csv\")\n",
    "partition_train_index=partition[(partition[\"Partition\"]==\"train\")][\"Id\"].to_numpy()\n",
    "partition_devel_index=partition[(partition[\"Partition\"]==\"devel\")][\"Id\"].to_numpy()\n",
    "partition_test_index=partition[(partition[\"Partition\"]==\"test\")][\"Id\"].to_numpy()\n",
    "partition_index = partition[(partition[\"Partition\"]==\"train\") | (partition[\"Partition\"]==\"devel\")|(partition[\"Partition\"]==\"test\")][\"Id\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ecg_signal= pd.read_csv(f\"/Thesis_data/c3_muse_stress_2022/feature_segments/ECG/1.csv\")\n",
    "arousal=pd.read_csv(f\"/Thesis_data/c3_muse_stress_2022/label_segments/physio-arousal/1.csv\")\n",
    "valence=pd.read_csv(f\"/Thesis_data/c3_muse_stress_2022/label_segments/valence/1.csv\")\n",
    "\n",
    "print(max(ecg_signal['ECG']))\n",
    "print(min(ecg_signal['ECG']))\n",
    "print(np.mean(ecg_signal['ECG']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valence and arousal plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [31]:\n",
    "        arousal=pd.read_csv(f\"/Thesis_data/c3_muse_stress_2022/label_segments/physio-arousal/31.csv\")\n",
    "        valence=pd.read_csv(f\"/Thesis_data/c3_muse_stress_2022/label_segments/valence/31.csv\")\n",
    "        plt.scatter(valence['value'],arousal['value'],s=2) \n",
    "        print(i)\n",
    "        plt.xlim(-1,1)\n",
    "        plt.ylim(-1,1)\n",
    "        ax=plt.gca()\n",
    "        circle=plt.Circle((0, 0), 0.2, color='r',fill=False)\n",
    "        ax.add_artist(circle)\n",
    "        plt.plot([-1,1],[0,0])\n",
    "        plt.plot([0,0],[-1,1])\n",
    "        plt.title('Label transformation for participant 31')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot of BPM variation for some participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col={}\n",
    "for i in partition_train_index:\n",
    "    ecg_signal_raw= pd.read_csv(f\"/Thesis_data/c3_muse_stress_2022/feature_segments/BPM/{i}.csv\")\n",
    "    col[i]=ecg_signal_raw['BPM']\n",
    "    #     sns.boxplot(x=ecg_signal_raw[\"BPM\"])\n",
    "df=pd.DataFrame(col)\n",
    "boxplot = df.boxplot(column=[i for i in partition_train_index[:20]]) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label tranformation following the procedure done by https://github.com/face-analysis/emonet/blob/master/emonet/data/affecnet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in labels:\n",
    "#     data=pd.read_csv(f\"D:/Thesis_data/c3_muse_stress_2022/label_segments/target_labels/{i}.csv\")\n",
    "#     one_hot_encoded_data = pd.get_dummies(data, columns = ['labels'])\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "import math\n",
    "label=[]\n",
    "label.extend(partition_train_index)\n",
    "label.extend(partition_devel_index)\n",
    "for i in label:\n",
    "    valence=pd.read_csv(f\"/Thesis_data/c3_muse_stress_2022/label_segments/valence/{i}.csv\")\n",
    "    arousal=pd.read_csv(f\"/Thesis_data/c3_muse_stress_2022/label_segments/physio-arousal/{i}.csv\")\n",
    "\n",
    "    # valence['value']=pd.cut(valence['value'], bins=np.linspace(-1,1, 3),labels=[False,True])\n",
    "    # arousal['value']=pd.cut(arousal['value'], bins=np.linspace(-1,1, 3),labels=[False,True])\n",
    "    target=pd.DataFrame()\n",
    "    target['timestamp']=valence['timestamp']\n",
    "    target['V_value']=valence['value']\n",
    "    target['A_value']=arousal['value']\n",
    "\n",
    "    target['label']=0\n",
    "    \n",
    "    target['intensity'] = np.sqrt(target['V_value']**2+target['A_value']**2)\n",
    "\n",
    "    mask_neutral = target['intensity']<0.2\n",
    "    mask_stressed=(target['A_value']>=0) & (target['V_value']<=0) & (target['intensity']>=0.2)\n",
    "    mask_nonstressed= ~(mask_neutral | mask_stressed)\n",
    "    \n",
    "    target['label'][mask_neutral] = 0\n",
    "\n",
    "    target['label'][mask_stressed] = 1\n",
    "     \n",
    "    target['label'][mask_nonstressed] = 2\n",
    "    \n",
    "    target.to_csv(f\"D:/Thesis_data/c3_muse_stress_2022/label_segments/target_labels/{i}.csv\",index=False)\n",
    "\n",
    "\n",
    "#     target['labels'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class distribution for the participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in partition_train_index:\n",
    "    if i<70:\n",
    "        target=pd.read_csv(f\"/Thesis_data/c3_muse_stress_2022/label_segments/target_labels/{i}.csv\")\n",
    "        print(i)\n",
    "        plt.hist(target['label'])  \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation for ML classification tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_signals_train=pd.DataFrame()\n",
    "\n",
    "for i in partition_train_index:\n",
    "    bio_signals=pd.read_csv(f\"/Thesis_data/c3_muse_stress_2022/feature_segments/Normalized_biosignals/{i}.csv\")\n",
    "    target=pd.read_csv(f\"/Thesis_data/c3_muse_stress_2022/label_segments/target_labels/{i}.csv\")\n",
    "\n",
    "    bio_signals=bio_signals[['subject_id','timestamp','ECG','resp','BPM']]\n",
    "    bio_signals['labels']=target['label']\n",
    "    bio_signals_train = pd.concat([bio_signals_train,bio_signals])\n",
    "    bio_signals_= pd.concat([bio_signals_,bio_signals_train, bio_signals],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_signals_validation=pd.DataFrame()\n",
    "for i in partition_devel_index:\n",
    "    bio_signals=pd.read_csv(f\"/Thesis_data/c3_muse_stress_2022/feature_segments/Normalized_biosignals/{i}.csv\")\n",
    "    target=pd.read_csv(f\"/Thesis_data/c3_muse_stress_2022/label_segments/target_labels/{i}.csv\")\n",
    "    fau=pd.read_csv(f\"/Thesis_data/c3_muse_stress_2022/feature_segments/faus/{i}.csv\")\n",
    "    fau.drop(['timestamp','subject_id'],axis=1,inplace=True)\n",
    "    bio_signals=bio_signals[['ECG','resp','BPM']]\n",
    "    bio_signals['labels']=target['label']\n",
    "    bio_signals_validation = pd.concat([bio_signals_validation, bio_signals])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "x=bio_signals_train[bio_signals_train.columns[2:-1]]\n",
    "y=bio_signals_train['labels'] \n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(x,y)\n",
    "\n",
    "y_pred=clf.predict(bio_signals_validation[x.columns])\n",
    "print(clf.score(bio_signals_validation[x.columns],bio_signals_validation['labels']))\n",
    "print(classification_report(bio_signals_validation['labels'], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(clf,bio_signals_validation[x.columns], bio_signals_validation['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf_svm = SVC(gamma='auto')\n",
    "clf_svm.fit(bio_signals_train[x.columns],bio_signals_train['labels'] )\n",
    "\n",
    "y_pred=clf_svm.predict(bio_signals_validation[x.columns])\n",
    "print(clf_svm.score(bio_signals_validation[x.columns],bio_signals_validation['labels']))\n",
    "print(classification_report(bio_signals_validation['labels'], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(clf_svm,bio_signals_validation[x.columns], bio_signals_validation['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xgboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "x=bio_signals_train[bio_signals_train.columns[2:-1]]\n",
    "y=bio_signals_train['labels'] \n",
    "\n",
    "# cross_val_score(XGBClassifier(), X, y)\n",
    "\n",
    "clf = XGBClassifier()\n",
    "clf.fit(x,y)\n",
    "\n",
    "y_pred=clf.predict(bio_signals_validation[x.columns])\n",
    "print(clf.score(bio_signals_validation[x.columns],bio_signals_validation['labels']))\n",
    "print(classification_report(bio_signals_validation['labels'], y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(clf,bio_signals_validation[x.columns], bio_signals_validation['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downsampling with random resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Non_stressed = bio_signals_train[bio_signals_train[\"labels\"] == 2]\n",
    "stressed  = bio_signals_train[bio_signals_train[\"labels\"] == 1]\n",
    "Neutral  = bio_signals_train[bio_signals_train[\"labels\"] == 0]\n",
    "\n",
    "print(Non_stressed.shape)\n",
    "print(stressed.shape)\n",
    "print(Neutral.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "Non_stressed = resample(Non_stressed,\n",
    "             replace=True,\n",
    "             n_samples=len(stressed),\n",
    "             random_state=42)\n",
    "Neutral = resample(Neutral,\n",
    "             replace=True,\n",
    "             n_samples=len(stressed),\n",
    "             random_state=42)\n",
    "\n",
    "print(Non_stressed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_signals_train = pd.concat([Non_stressed, stressed, Neutral])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(bio_signals_train['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_signals_validation=pd.DataFrame()\n",
    "for i in partition_devel_index:\n",
    "    bio_signals=pd.read_csv(f\"/Thesis_data/c3_muse_stress_2022/feature_segments/biosignals/{i}.csv\")\n",
    "    target=pd.read_csv(f\"/Thesis_data/c3_muse_stress_2022/label_segments/target_labels/{i}.csv\")\n",
    "    fau=pd.read_csv(f\"/Thesis_data/c3_muse_stress_2022/feature_segments/faus/{i}.csv\")\n",
    "    fau.drop(['timestamp','subject_id'],axis=1,inplace=True)\n",
    "    bio_signals=bio_signals[['ECG','resp','BPM']]\n",
    "#     valence=valence[['value']]\n",
    "#     bio_signals[fau.columns]=fau[fau.columns]\n",
    "    bio_signals['labels']=target['label']\n",
    "    bio_signals_validation = pd.concat([bio_signals_validation, bio_signals])\n",
    "# bio_signals_validation['BPM'] = zscore(bio_signals_validation['BPM'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "x=bio_signals_train[bio_signals_train.columns[2:-1]]\n",
    "y=bio_signals_train['labels'] \n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(x,y)\n",
    "y_pred=clf.predict(bio_signals_validation[x.columns])\n",
    "print(clf.score(bio_signals_validation[x.columns],bio_signals_validation['labels']))\n",
    "print(classification_report(bio_signals_validation['labels'], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(clf,bio_signals_validation[x.columns], bio_signals_validation['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Svm classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf_svm = SVC(gamma='auto')\n",
    "clf_svm.fit(bio_signals_train[x.columns],bio_signals_train['labels'] )\n",
    "y_pred=clf_svm.predict(bio_signals_validation[x.columns])\n",
    "\n",
    "print(clf_svm.score(bio_signals_validation[x.columns],bio_signals_validation['labels']))\n",
    "print(classification_report(bio_signals_validation['labels'], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(clf_svm,bio_signals_validation[x.columns], bio_signals_validation['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xgboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "x=bio_signals_train[bio_signals_train.columns[2:-1]]\n",
    "y=bio_signals_train['labels'] \n",
    "\n",
    "# cross_val_score(XGBClassifier(), X, y)\n",
    "\n",
    "clf = XGBClassifier()\n",
    "clf.fit(x,y)\n",
    "\n",
    "y_pred=clf.predict(bio_signals_validation[x.columns])\n",
    "print(clf.score(bio_signals_validation[x.columns],bio_signals_validation['labels']))\n",
    "print(classification_report(bio_signals_validation['labels'], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(clf,bio_signals_validation[x.columns], bio_signals_validation['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upsampling with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from collections import Counter\n",
    "\n",
    "x=bio_signals_train[bio_signals_train.columns[2:-1]]\n",
    "y=bio_signals_train['labels']\n",
    "\n",
    "X_resampled, y_resampled = SMOTE().fit_resample(x, y)\n",
    "print(Counter(y_resampled))\n",
    "# print(sorted(Counter(y_resampled).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "x=bio_signals_train[bio_signals_train.columns[2:-1]]\n",
    "y=bio_signals_train['labels']\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_resampled, y_resampled)\n",
    "\n",
    "y_pred=clf.predict(bio_signals_validation[x.columns])\n",
    "print(clf.score(bio_signals_validation[x.columns],bio_signals_validation['labels']))\n",
    "print(classification_report(bio_signals_validation['labels'], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(clf,bio_signals_validation[x.columns], bio_signals_validation['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM classifier_upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf_svm = SVC(gamma='auto')\n",
    "clf_svm.fit(X_resampled, y_resampled)\n",
    "\n",
    "y_pred=clf_svm.predict(bio_signals_validation[x.columns])\n",
    "\n",
    "print(clf_svm.score(bio_signals_validation[x.columns],bio_signals_validation['labels']))\n",
    "print(classification_report(bio_signals_validation['labels'], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(clf,bio_signals_validation[x.columns], bio_signals_validation['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xgboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "x=bio_signals_train[bio_signals_train.columns[2:-1]]\n",
    "y=bio_signals_train['labels'] \n",
    "\n",
    "# cross_val_score(XGBClassifier(), X, y)\n",
    "\n",
    "clf = XGBClassifier()\n",
    "clf.fit(X_resampled, y_resampled)\n",
    "\n",
    "y_pred=clf.predict(bio_signals_validation[x.columns])\n",
    "print(clf.score(bio_signals_validation[x.columns],bio_signals_validation['labels']))\n",
    "print(classification_report(bio_signals_validation['labels'], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(clf,bio_signals_validation[x.columns], bio_signals_validation['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UMAP projection of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "reducer = umap.UMAP()\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_signals_train=pd.DataFrame()\n",
    "\n",
    "for i in partition_train_index:\n",
    "    bio_signals=pd.read_csv(f\"/Thesis_data/c3_muse_stress_2022/feature_segments/biosignals/{i}.csv\")\n",
    "    target=pd.read_csv(f\"/Thesis_data/c3_muse_stress_2022/label_segments/target_labels/{i}.csv\")\n",
    "    bio_signals=bio_signals[['subject_id','timestamp','ECG','resp','BPM']]\n",
    "#     valence=valence[['value']]\n",
    "    bio_signals['labels']=target['label']\n",
    "    bio_signals_train = pd.concat([bio_signals_train,bio_signals])\n",
    "#     bio_signals_= pd.concat([bio_signals_,bio_signals_train, bio_signals],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = reducer.fit_transform(scaled_data)\n",
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=['Neutral','Stressed','Non-stressed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    embedding[:, 0],\n",
    "    embedding[:, 1],\n",
    "    c=bio_signals_train.labels)\n",
    "#     c = bio_signals_train['labels'])\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "cbar = plt.colorbar(boundaries=np.arange(4) -0.5 )\n",
    "cbar.set_ticks(np.arange(3))\n",
    "# cbar.set_ticklabels(bio_signals_train.labels)\n",
    "cbar.set_ticklabels(classes)\n",
    "plt.title('UMAP projection of the biosignals features', fontsize=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_signals_train.labels.map({\"Neutral\": 0, \"Stressed\": 1, \"Non_stressed\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Non_stressed = bio_signals_train[bio_signals_train[\"labels\"] == \"Non_stressed\"]\n",
    "stressed  = bio_signals_train[bio_signals_train[\"labels\"] == \"Stressed\"]\n",
    "Neutral  = bio_signals_train[bio_signals_train[\"labels\"] == \"Neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def bar_plot(ax, data, colors=None, total_width=0.8, single_width=1, legend=True):\n",
    "    \"\"\"Draws a bar plot with multiple bars per data point.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ax : matplotlib.pyplot.axis\n",
    "        The axis we want to draw our plot on.\n",
    "\n",
    "    data: dictionary\n",
    "        A dictionary containing the data we want to plot. Keys are the names of the\n",
    "        data, the items is a list of the values.\n",
    "\n",
    "        Example:\n",
    "        data = {\n",
    "            \"x\":[1,2,3],\n",
    "            \"y\":[1,2,3],\n",
    "            \"z\":[1,2,3],\n",
    "        }\n",
    "\n",
    "    colors : array-like, optional\n",
    "        A list of colors which are used for the bars. If None, the colors\n",
    "        will be the standard matplotlib color cyle. (default: None)\n",
    "\n",
    "    total_width : float, optional, default: 0.8\n",
    "        The width of a bar group. 0.8 means that 80% of the x-axis is covered\n",
    "        by bars and 20% will be spaces between the bars.\n",
    "\n",
    "    single_width: float, optional, default: 1\n",
    "        The relative width of a single bar within a group. 1 means the bars\n",
    "        will touch eachother within a group, values less than 1 will make\n",
    "        these bars thinner.\n",
    "\n",
    "    legend: bool, optional, default: True\n",
    "        If this is set to true, a legend will be added to the axis.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if colors where provided, otherwhise use the default color cycle\n",
    "    \n",
    "    if colors is None:\n",
    "        colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "    # Number of bars per group\n",
    "    n_bars = len(data)\n",
    "\n",
    "    # The width of a single bar\n",
    "    bar_width = total_width / n_bars\n",
    "\n",
    "    # List containing handles for the drawn bars, used for the legend\n",
    "    bars = []\n",
    "\n",
    "    # Iterate over all data\n",
    "    for i, (name, values) in enumerate(data.items()):\n",
    "        # The offset in x direction of that bar\n",
    "        x_offset = (i - n_bars / 2) * bar_width + bar_width / 2\n",
    "\n",
    "        # Draw a bar for every value of that type\n",
    "        for x, y in enumerate(values):\n",
    "            bar = ax.bar(x + x_offset, y, width=bar_width * single_width, color=colors[i % len(colors)])\n",
    "\n",
    "        # Add a handle to the last drawn bar, which we'll need for the legend\n",
    "        bars.append(bar[0])\n",
    "\n",
    "    # Draw legend if we need\n",
    "    if legend:\n",
    "        ax.legend(bars, data.keys())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Usage example:\n",
    "    N = 3\n",
    "    ind = np.arange(N)  # the x locations for the groups\n",
    "#     width = 0.08 \n",
    "    data = {\n",
    "        \"Neutral\": [4831, 17592, 2289],\n",
    "        \"Stressed\": [2289, 17592, 2289],\n",
    "        \"Non-stressed\": [17592, 17592, 2289],\n",
    "    }\n",
    "    fig, ax = plt.subplots()\n",
    "    bar_plot(ax, data, total_width=.8, single_width=.9)\n",
    "    ax.set_xticks(ind)\n",
    "    ax.set_xticklabels( ('original Label distribution', 'After SMOTE', 'After re-sample') )\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting the model with one participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_signals_validation=pd.DataFrame()\n",
    "# for i in partition_devel_index:\n",
    "bio_signals=pd.read_csv(f\"/Thesis_data/c3_muse_stress_2022/feature_segments/biosignals/20.csv\")\n",
    "target=pd.read_csv(f\"/Thesis_data/c3_muse_stress_2022/label_segments/target_labels/20.csv\")\n",
    "#     fau=pd.read_csv(f\"/Thesis_data/c3_muse_stress_2022/feature_segments/faus/{i}.csv\")\n",
    "#     fau.drop(['timestamp','subject_id'],axis=1,inplace=True)\n",
    "bio_signals=bio_signals[['ECG','resp','BPM']]\n",
    "#     valence=valence[['value']]\n",
    "bio_signals['labels']=target['label']\n",
    "bio_signals_validation = pd.concat([bio_signals_validation, bio_signals])\n",
    "# bio_signals_validation['BPM'] = zscore(bio_signals_validation['BPM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "x=bio_signals_train[bio_signals_train.columns[2:-1]]\n",
    "y=bio_signals_train['labels'] \n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(bio_signals_validation[x.columns])\n",
    "print(clf.score(bio_signals_validation[x.columns],bio_signals_validation['labels']))\n",
    "print(classification_report(bio_signals_validation['labels'], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "plot_confusion_matrix(clf,bio_signals_validation[x.columns], bio_signals_validation['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(bio_signals_train['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "x=bio_signals_train[bio_signals_train.columns[2:-1]]\n",
    "y=bio_signals_train['labels'] \n",
    "\n",
    "# cross_val_score(XGBClassifier(), X, y)\n",
    "\n",
    "clf = XGBClassifier()\n",
    "clf.fit(x,y)\n",
    "\n",
    "y_pred=clf.predict(bio_signals_validation[x.columns])\n",
    "print(clf.score(bio_signals_validation[x.columns],bio_signals_validation['labels']))\n",
    "print(classification_report(bio_signals_validation['labels'], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "plot_confusion_matrix(clf,bio_signals_validation[x.columns], bio_signals_validation['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing the features with Minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "# scaled = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in labels:\n",
    "#     data=pd.read_csv(f\"D:/Thesis_data/c3_muse_stress_2022/label_segments/target_labels/{i}.csv\")\n",
    "#     one_hot_encoded_data = pd.get_dummies(data, columns = ['labels'])\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "import math\n",
    "label=[]\n",
    "label.extend(partition_train_index)\n",
    "label.extend(partition_devel_index)\n",
    "label.extend(partition_test_index)\n",
    "for i in label:\n",
    "    Biosignals=pd.read_csv(f\"/Thesis_data/c3_muse_stress_2022/feature_segments/biosignals/{i}.csv\")\n",
    "\n",
    "    target=pd.DataFrame()\n",
    "    target=Biosignals[['timestamp','subject_id','ECG','resp','BPM']]\n",
    "    target[['ECG','resp','BPM']] = scaler.fit_transform(Biosignals[['ECG','resp','BPM']])\n",
    "#     target['timestamp']=Biosignals['timestamp']\n",
    "    print(target)\n",
    "\n",
    "  \n",
    "    target.to_csv(f\"D:/Thesis_data/c3_muse_stress_2022/feature_segments/Normalized_biosignals/{i}.csv\",index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valence and arousal distribution of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_arousal=[]\n",
    "devel_arousal=[]\n",
    "for i in partition_train_index:\n",
    "    arousal=pd.read_csv(f\"/Thesis_data/c3_muse_stress_2022/label_segments/physio-arousal/{i}.csv\")\n",
    "    train_arousal.extend(arousal['value'])\n",
    "for i in partition_devel_index:\n",
    "    arousal=pd.read_csv(f\"/Thesis_data/c3_muse_stress_2022/label_segments/physio-arousal/{i}.csv\")\n",
    "    devel_arousal.extend(arousal['value'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(train_arousal, label='train')\n",
    "sns.kdeplot(devel_arousal, label='devel')\n",
    "print(np.mean(train_arousal))\n",
    "print(np.mean(devel_arousal))\n",
    "\n",
    "print(np.std(train_arousal))\n",
    "print(np.std(devel_arousal))\n",
    "\n",
    "# Set the title and axis labels\n",
    "plt.title(\"Arousal value distribution\")\n",
    "plt.xlabel(\"Values\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
