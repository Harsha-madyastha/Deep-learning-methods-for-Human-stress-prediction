{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe95d3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc0776e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training,test,devel data index extraction from partition file\n",
    "partition  = pd.read_csv(f\"/Thesis_data/c3_muse_stress_2022/metadata/partition.csv\")\n",
    "partition_train_index=partition[(partition[\"Partition\"]==\"train\")][\"Id\"].to_numpy()\n",
    "partition_devel_index=partition[(partition[\"Partition\"]==\"devel\")][\"Id\"].to_numpy()\n",
    "partition_test_index=partition[(partition[\"Partition\"]==\"test\")][\"Id\"].to_numpy()\n",
    "partition_index = partition[(partition[\"Partition\"]==\"train\") | (partition[\"Partition\"]==\"devel\")|(partition[\"Partition\"]==\"test\")][\"Id\"].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daefac9b",
   "metadata": {},
   "source": [
    "## FAU extraction Procedure using pyfeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1318213e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feat import Detector\n",
    "import feat\n",
    "from feat.utils.io import read_feat\n",
    "\n",
    "\n",
    "detector = Detector(\n",
    "    face_model=\"retinaface\",\n",
    "    landmark_model=\"mobilefacenet\",\n",
    "    au_model='xgb',\n",
    "    emotion_model=\"resmasknet\",\n",
    "    facepose_model=\"img2pose\",\n",
    ")\n",
    "\n",
    "from feat.utils.io import get_test_data_path\n",
    "from feat.plotting import imshow\n",
    "import os\n",
    "\n",
    "# Helper to point to the test data folder\n",
    "test_data_dir = get_test_data_path()\n",
    "\n",
    "# Get the full path\n",
    "single_face_img_path = os.path.join(\"./c3_muse_stress_2022/raw_data/faces/2/\", \"11000.jpg\")\n",
    "\n",
    "# Plot it\n",
    "single_face_prediction = detector.detect_image(single_face_img_path)\n",
    "\n",
    "single_face_prediction.facebox\n",
    "single_face_prediction.aus\n",
    "single_face_prediction.emotions\n",
    "single_face_prediction.facepose # (in degrees)\n",
    "single_face_prediction.to_csv(\"output3.csv\", index=False)\n",
    "\n",
    "# input_prediction = read_feat(\"output3.csv\")\n",
    "# figs = single_face_prediction.plot_detections(poses=True)\n",
    "\n",
    "# plt.savefig(\"pitch.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c35760",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = os.path.join(\"/Thesis_data/c3_muse_stress_2022/raw_data/faces/2/0.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfb90c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "f, ax = plt.subplots()\n",
    "im = Image.open(single_face_img_path)\n",
    "ax.imshow(im);\n",
    "old_size=im.size\n",
    "new_size = (200, 200)\n",
    "new_im = Image.new(\"RGB\", new_size)   ## luckily, this is already black!\n",
    "box = tuple((n - o) // 2 for n, o in zip(new_size, old_size))\n",
    "new_im.paste(im, box)\n",
    "\n",
    "new_im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46665bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "img = Image.open(test_image)\n",
    "img_with_border = ImageOps.expand(img,border=25,fill='white')\n",
    "img_with_border.save('imaged-with-border2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f44f642",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_prediction = detector.detect_image(test_image)\n",
    "# Show results\n",
    "image_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ce9da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "figs = single_face_prediction.plot_detections(poses=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8f23f3",
   "metadata": {},
   "source": [
    "## Spectrogram extraction using parselmouth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd24fa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import parselmouth\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set() # Use seaborn's default style to make attractive graphs\n",
    "plt.rcParams['figure.dpi'] = 100 # Show nicely large images in this notebook\n",
    "\n",
    "snd = parselmouth.Sound(\"audio/the_north_wind_and_the_sun.wav\")\n",
    "plt.figure()\n",
    "plt.plot(snd.xs(), snd.values.T)\n",
    "plt.xlim([snd.xmin, snd.xmax])\n",
    "plt.xlabel(\"time [s]\")\n",
    "plt.ylabel(\"amplitude\")\n",
    "# plt.show() # or \n",
    "plt.savefig(\"sound.png\")\n",
    "\n",
    "def draw_spectrogram(spectrogram, dynamic_range=70):\n",
    "    X, Y = spectrogram.x_grid(), spectrogram.y_grid()\n",
    "    sg_db = 10 * np.log10(spectrogram.values)\n",
    "    plt.pcolormesh(X, Y, sg_db, vmin=sg_db.max() - dynamic_range, cmap='afmhot')\n",
    "    plt.ylim([spectrogram.ymin, spectrogram.ymax])\n",
    "    plt.xlabel(\"time [s]\")\n",
    "    plt.ylabel(\"frequency [Hz]\")\n",
    "\n",
    "def draw_intensity(intensity):\n",
    "    plt.plot(intensity.xs(), intensity.values.T, linewidth=3, color='w')\n",
    "    plt.plot(intensity.xs(), intensity.values.T, linewidth=1)\n",
    "    plt.grid(False)\n",
    "    plt.ylim(0)\n",
    "    plt.ylabel(\"intensity [dB]\")\n",
    "\n",
    "intensity = snd.to_intensity()\n",
    "spectrogram = snd.to_spectrogram()\n",
    "plt.figure()\n",
    "draw_spectrogram(spectrogram)\n",
    "plt.twinx()\n",
    "draw_intensity(intensity)\n",
    "plt.xlim([snd.xmin, snd.xmax])\n",
    "\n",
    "plt.savefig(\"sound1.png\")\n",
    "\n",
    "def draw_pitch(pitch):\n",
    "    # Extract selected pitch contour, and\n",
    "    # replace unvoiced samples by NaN to not plot\n",
    "    pitch_values = pitch.selected_array['frequency']\n",
    "    pitch_values[pitch_values==0] = np.nan\n",
    "    plt.plot(pitch.xs(), pitch_values, 'o', markersize=5, color='w')\n",
    "    plt.plot(pitch.xs(), pitch_values, 'o', markersize=2)\n",
    "    plt.grid(False)\n",
    "    plt.ylim(0, pitch.ceiling)\n",
    "    plt.ylabel(\"fundamental frequency [Hz]\")\n",
    "\n",
    "pitch = snd.to_pitch()\n",
    "# If desired, pre-emphasize the sound fragment before calculating the spectrogram\n",
    "pre_emphasized_snd = snd.copy()\n",
    "pre_emphasized_snd.pre_emphasize()\n",
    "spectrogram = pre_emphasized_snd.to_spectrogram(window_length=0.03, maximum_frequency=8000)\n",
    "plt.figure()\n",
    "draw_spectrogram(spectrogram)\n",
    "plt.twinx()\n",
    "draw_pitch(pitch)\n",
    "plt.xlim([snd.xmin, snd.xmax])\n",
    "plt.savefig(\"pitch.png\")\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
